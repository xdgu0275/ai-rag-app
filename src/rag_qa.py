# src/rag_qa.py - å®Œæ•´çš„ RAG é—®ç­”ç³»ç»Ÿï¼ˆæ£€ç´¢ + ç”Ÿæˆ + å¼•ç”¨ï¼‰
import os
import logging
import time
import requests
from typing import List, Optional, Dict, Any

from langchain_chroma import Chroma
from chromadb.config import Settings
from langchain.schema import Document
import dashscope
import dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
dotenv.load_dotenv()

# æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
)
logger = logging.getLogger(__name__)

# ================== é€šä¹‰åƒé—®æ–‡æœ¬ç”Ÿæˆç±» ==================
class QwenTextGeneration:
    """å°è£…é€šä¹‰åƒé—®æ–‡æœ¬ç”ŸæˆAPIè°ƒç”¨"""
    def __init__(self, model: str = "qwen3-30b-a3b-thinking-2507"):
        self.model = model
        self.MAX_RETRIES = 3
        self.REQUEST_INTERVAL = 12
        
        # ä»ç¯å¢ƒå˜é‡è·å–API Key
        self.api_key = os.getenv("DASHSCOPE_API_KEY")
        if not self.api_key:
            raise ValueError("è¯·è®¾ç½®ç¯å¢ƒå˜é‡ DASHSCOPE_API_KEY")
        
    def generate(self, prompt: str, history: Optional[List[Dict[str, str]]] = None) -> str:
        """ç”Ÿæˆæ–‡æœ¬å“åº”
        Args:
            prompt: ç”¨æˆ·è¾“å…¥çš„æç¤º
            history: å¯¹è¯å†å²
        Returns:
            ç”Ÿæˆçš„æ–‡æœ¬å“åº”
        """
        retry_count = 0
        while retry_count < self.MAX_RETRIES:
            try:
                logger.info(f"ğŸ“¤ å‘é€æ–‡æœ¬ç”Ÿæˆè¯·æ±‚ (æ¨¡å‹: {self.model}, é‡è¯•: {retry_count}/{self.MAX_RETRIES-1})")
                
                url = "https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation"
                headers = {
                    "Authorization": f"Bearer {self.api_key}",
                    "Content-Type": "application/json"
                }
                
                # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
                messages = []
                if history:
                    messages.extend(history)
                messages.append({"role": "user", "content": prompt})
                
                data = {
                    "model": self.model,
                    "input": {"messages": messages}
                }
                
                response = requests.post(url, json=data, headers=headers)
                logger.info(f"ğŸ“¥ æ”¶åˆ°æ–‡æœ¬ç”Ÿæˆå“åº”: çŠ¶æ€ç  {response.status_code}")
                
                if response.status_code == 200:
                    result = response.json()
                    logger.info(f"ğŸ“ APIå“åº”å†…å®¹: {result}")  # æ‰“å°å®Œæ•´å“åº”ï¼Œç”¨äºè°ƒè¯•
                    
                    # å°è¯•ä¸åŒçš„å“åº”è§£ææ–¹å¼
                    if "output" in result:
                        # æ£€æŸ¥æ˜¯å¦ç›´æ¥æœ‰textå­—æ®µ
                        if "text" in result["output"]:
                            return result["output"]["text"]
                        # æ£€æŸ¥æ˜¯å¦æœ‰choiceså­—æ®µ
                        elif "choices" in result["output"] and len(result["output"]["choices"]) > 0:
                            if "message" in result["output"]["choices"][0] and "content" in result["output"]["choices"][0]["message"]:
                                return result["output"]["choices"][0]["message"]["content"]
                            elif "text" in result["output"]["choices"][0]:
                                return result["output"]["choices"][0]["text"]
                    elif "result" in result:
                        return result["result"]
                    
                    # å¦‚æœæ‰€æœ‰å°è¯•éƒ½å¤±è´¥ï¼ŒæŠ›å‡ºå¼‚å¸¸
                    raise Exception(f"APIå“åº”æ ¼å¼ä¸æ­£ç¡®ï¼Œé¢„æœŸç»“æ„æœªæ‰¾åˆ°ã€‚å“åº”: {result}")
                elif response.status_code in [429, 500, 502, 503, 504]:
                    # é™æµæˆ–æœåŠ¡å™¨é”™è¯¯ï¼Œé‡è¯•
                    retry_count += 1
                    wait_time = self.REQUEST_INTERVAL * (2 ** retry_count)  # æŒ‡æ•°é€€é¿
                    logger.warning(f"âš ï¸ APIé”™è¯¯: {response.status_code}, ç­‰å¾… {wait_time} ç§’åé‡è¯•")
                    time.sleep(wait_time)
                else:
                    raise Exception(f"APIé”™è¯¯: {response.status_code} - {response.text}")
            except Exception as e:
                retry_count += 1
                logger.error(f"âŒ æ–‡æœ¬ç”Ÿæˆè°ƒç”¨å¤±è´¥: {str(e)}, é‡è¯• {retry_count}/{self.MAX_RETRIES-1}")
                if retry_count < self.MAX_RETRIES:
                    wait_time = self.REQUEST_INTERVAL * (2 ** retry_count)
                    time.sleep(wait_time)
                else:
                    raise


# ================== é€šä¹‰åƒé—® Embedding ç±» ==================
class QwenEmbeddings:
    """å°è£…é€šä¹‰åƒé—® Embedding API è°ƒç”¨"""
    def __init__(self, model: str = "text-embedding-v4"):
        self.model = model
        self.MAX_RETRIES = 3
        self.REQUEST_INTERVAL = 12
        self.BATCH_SIZE = 5

    def _call_api(self, texts: List[str]) -> List[List[float]]:
        """è°ƒç”¨ DashScope Embedding APIï¼Œä»…ä½¿ç”¨HTTPè°ƒç”¨æ–¹å¼"""
        retry_count = 0
        while retry_count < self.MAX_RETRIES:
            try:
                logger.info(f"ğŸ“¤ å‘é€HTTPè¯·æ±‚: {len(texts)} ä¸ªæ–‡æœ¬ (é‡è¯•: {retry_count}/{self.MAX_RETRIES-1})")
                
                # ä½¿ç”¨å…¼å®¹æ¨¡å¼API URL
                url = "https://dashscope.aliyuncs.com/compatible-mode/v1/embeddings"
                headers = {
                    "Authorization": f"Bearer {dashscope.api_key}",
                    "Content-Type": "application/json"
                }
                
                data = {
                    "model": self.model,
                    "input": texts,
                    "dimensions": 1024,
                    "encoding_format": "float"
                }
                response = requests.post(url, json=data, headers=headers)
                logger.info(f"ğŸ“¥ æ”¶åˆ° HTTP å“åº”: çŠ¶æ€ç  {response.status_code}")
                if response.status_code == 200:
                        result = response.json()
                        # æ£€æŸ¥å“åº”ç»“æ„
                        if "data" not in result:
                            raise Exception("HTTP API å“åº”æ ¼å¼ä¸æ­£ç¡®ï¼Œç¼ºå°‘ data å­—æ®µ")
                        embeddings_data = [item["embedding"] for item in result["data"]]
                        results = embeddings_data
                        logger.info(f"âœ… æˆåŠŸè·å– {len(results)} ä¸ªåµŒå…¥å‘é‡")
                        return results
                elif response.status_code in [429, 500, 502, 503, 504]:
                        # é™æµæˆ–æœåŠ¡å™¨é”™è¯¯ï¼Œé‡è¯•
                        retry_count += 1
                        wait_time = self.REQUEST_INTERVAL * (2 ** retry_count)  # æŒ‡æ•°é€€é¿
                        logger.warning(f"âš ï¸ HTTP API é”™è¯¯: çŠ¶æ€ç  {response.status_code}, å“åº”: {response.text}, ç­‰å¾… {wait_time} ç§’åé‡è¯•")
                        time.sleep(wait_time)
                        if retry_count >= self.MAX_RETRIES:
                            raise Exception(f"HTTP API é‡è¯•æ¬¡æ•°è¾¾åˆ°ä¸Šé™ {self.MAX_RETRIES} æ¬¡")
                else:
                        raise Exception(f"HTTP API é”™è¯¯: çŠ¶æ€ç  {response.status_code}, å“åº”: {response.text}")
            except Exception as e:
                retry_count += 1
                logger.error(f"âŒ Embedding è°ƒç”¨å¤±è´¥: {str(e)}, é‡è¯• {retry_count}/{self.MAX_RETRIES-1}")
                if retry_count < self.MAX_RETRIES:
                    wait_time = self.REQUEST_INTERVAL * (2 ** retry_count)
                    time.sleep(wait_time)
                else:
                    raise

    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        """æ‰¹é‡ç”Ÿæˆæ–‡æ¡£åµŒå…¥ï¼ˆè‡ªåŠ¨åˆ†æ‰¹ï¼‰"""
        all_embeddings = []
        for i in range(0, len(texts), self.BATCH_SIZE):
            batch = texts[i:i+self.BATCH_SIZE]
            batch_num = i // self.BATCH_SIZE + 1
            logger.info(f"ğŸŒ è°ƒç”¨é€šä¹‰åƒé—® Embedding (æ‰¹æ¬¡: {batch_num}/{(len(texts)-1)//self.BATCH_SIZE + 1}, æ•°é‡: {len(batch)})")
            batch_embeds = self._call_api(batch)
            all_embeddings.extend(batch_embeds)
            logger.info(f"âœ… æ‰¹æ¬¡ {batch_num} å¤„ç†å®Œæˆ")
            # é¿å…é™æµ
            if i + self.BATCH_SIZE < len(texts):  # ä¸æ˜¯æœ€åä¸€æ‰¹æ‰éœ€è¦ç­‰å¾…
                time.sleep(self.REQUEST_INTERVAL)
        return all_embeddings

    def embed_query(self, text: str) -> List[float]:
        """ä¸ºæŸ¥è¯¢ç”ŸæˆåµŒå…¥"""
        return self._call_api([text])[0]

# ================== é…ç½® ==================
DASHSCOPE_API_KEY = os.getenv("DASHSCOPE_API_KEY")
if not DASHSCOPE_API_KEY:
    raise ValueError("è¯·è®¾ç½®ç¯å¢ƒå˜é‡ DASHSCOPE_API_KEY")

dashscope.api_key = DASHSCOPE_API_KEY

# å‘é‡åº“è·¯å¾„ï¼ˆä¸split_text.pyä¿æŒä¸€è‡´ï¼‰
VECTOR_DB_PATH = os.getenv("VECTOR_DB_PATH", "vectorstore_qwen")
os.makedirs(VECTOR_DB_PATH, exist_ok=True)

# å¤§æ¨¡å‹é…ç½®
LLM_MODEL = "qwen-max"  # å¯é€‰: qwen-plus, qwen-turbo
EMBEDDING_MODEL = "text-embedding-v4"  # ä¸split_text.pyä¿æŒä¸€è‡´

# ================== åŠ è½½å‘é‡åº“ ==================
def load_vectorstore():
    """åŠ è½½ä¹‹å‰åˆ›å»ºçš„å‘é‡åº“"""
    try:
        # æ‰“å°å‘é‡åº“è·¯å¾„çš„ç»å¯¹è·¯å¾„ï¼Œç”¨äºè°ƒè¯•
        abs_vector_path = os.path.abspath(VECTOR_DB_PATH)
        logger.info(f"ğŸ” å°è¯•åŠ è½½å‘é‡åº“ï¼Œç»å¯¹è·¯å¾„: {abs_vector_path}")
        
        # ç¦ç”¨ Chroma telemetry
        os.environ["CHROMA_TELEMETRY_ENABLED"] = "false"
        logger.info("ğŸ”§ å·²ç¦ç”¨ Chroma telemetry")
        
        # ä¸split_text.pyä¿æŒä¸€è‡´ï¼Œä½¿ç”¨ç›¸åŒçš„åµŒå…¥æ¨¡å‹
        embeddings = QwenEmbeddings()
        logger.info(f"âœ… åˆå§‹åŒ–åµŒå…¥æ¨¡å‹: {embeddings.model}")

        # æ·»åŠ å‘é‡åº“é…ç½®è°ƒè¯•ä¿¡æ¯
        logger.info(f"ğŸ” å‘é‡åº“é…ç½®: ç»å¯¹è·¯å¾„={abs_vector_path}, é›†åˆåç§°=qwen_rag, åµŒå…¥æ¨¡å‹={embeddings.model}")
        
        # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
        if not os.path.exists(abs_vector_path):
            logger.error(f"âŒ å‘é‡åº“ç›®å½•ä¸å­˜åœ¨: {abs_vector_path}")
            return None
        
        # æ£€æŸ¥ç›®å½•æ˜¯å¦éç©º
        if len(os.listdir(abs_vector_path)) == 0:
            logger.error(f"âŒ å‘é‡åº“ç›®å½•ä¸ºç©º: {abs_vector_path}")
            return None
        
        # æ‰“å°ç›®å½•å†…å®¹ï¼Œç”¨äºè°ƒè¯•
        logger.info(f"ğŸ“‚ å‘é‡åº“ç›®å½•å†…å®¹: {os.listdir(abs_vector_path)}")
        
        # ä½¿ç”¨PersistentClientç›´æ¥è¿æ¥å‘é‡åº“
        from chromadb import PersistentClient
        client = PersistentClient(path=abs_vector_path)
        logger.info(f"âœ… æˆåŠŸåˆå§‹åŒ–PersistentClient")
        
        # è·å–é›†åˆ - ä¸ä¼ å…¥embedding_functionï¼Œä½¿ç”¨å·²å­˜å‚¨çš„åµŒå…¥
        try:
            collection = client.get_collection(
                name="qwen_rag"
            )
            logger.info(f"âœ… æˆåŠŸè®¿é—®é›†åˆ: qwen_rag")
            
            # æ£€æŸ¥æ–‡æ¡£æ•°é‡
            doc_count = collection.count()
            logger.info(f"ğŸ“Š é›†åˆæ–‡æ¡£æ•°é‡: {doc_count}")
            
            # åˆ›å»ºChromaå‘é‡åº“å®ä¾‹
            db = Chroma(
                client=client,
                collection_name="qwen_rag",
                embedding_function=embeddings
            )
            logger.info(f"âœ… å‘é‡åº“åŠ è½½å®Œæˆ")
            
            # æ‰“å°Chromaå®¢æˆ·ç«¯é…ç½®ï¼Œç”¨äºè°ƒè¯•
            logger.info(f"ğŸ” å‘é‡åº“å®¢æˆ·ç«¯ç±»å‹: {type(db._client)}")
            
            # æ£€æŸ¥å‘é‡åº“è¿æ¥æ˜¯å¦æ­£å¸¸
            try:
                # æ‰§è¡Œä¸€ä¸ªç®€å•çš„æŸ¥è¯¢
                test_query = "æµ‹è¯•æŸ¥è¯¢"
                test_embedding = embeddings.embed_query(test_query)
                logger.info(f"âœ… ç”Ÿæˆæµ‹è¯•æŸ¥è¯¢åµŒå…¥æˆåŠŸï¼Œå‘é‡é•¿åº¦: {len(test_embedding)}")
            except Exception as e:
                logger.error(f"âŒ ç”Ÿæˆæµ‹è¯•æŸ¥è¯¢åµŒå…¥å¤±è´¥: {e}")
            
            return db
        except Exception as e:
            logger.error(f"âŒ æ— æ³•è®¿é—®é›†åˆ qwen_rag: {str(e)}")
            return None
    except Exception as e:
        logger.error(f"âŒ åŠ è½½å‘é‡åº“å¤±è´¥: {e}")
        return None

# ================== RAG é—®ç­”å‡½æ•° ==================
def ask_rag_question(question: str, k: int = 2):
    """
    æ‰§è¡Œ RAG é—®ç­”
    :param question: ç”¨æˆ·é—®é¢˜
    :param k: è¿”å› top-k ä¸ªç›¸å…³ç‰‡æ®µ
    """
    db = load_vectorstore()
    if not db:
        return

    logger.info(f"ğŸ“ ç”¨æˆ·æé—®: {question}")
    logger.info(f"ğŸ” æ­£åœ¨æ£€ç´¢æœ€ç›¸å…³çš„ {k} ä¸ªæ–‡æ¡£ç‰‡æ®µ...")

    # 1. æ£€ç´¢
    try:
        # æ·»åŠ æ£€ç´¢å‚æ•°è°ƒè¯•ä¿¡æ¯
        logger.info(f"ğŸ” æ£€ç´¢å‚æ•°: é—®é¢˜='{question}', k={k}")
        
        # ç”ŸæˆæŸ¥è¯¢åµŒå…¥
        embeddings = QwenEmbeddings(model=EMBEDDING_MODEL)
        query_embedding = embeddings.embed_query(question)
        logger.info(f"âœ… ç”ŸæˆæŸ¥è¯¢åµŒå…¥æˆåŠŸï¼Œå‘é‡é•¿åº¦: {len(query_embedding)}")
        
        # æ‰§è¡Œæ£€ç´¢
        docs = db.similarity_search_by_vector(query_embedding, k=k)
        logger.info(f"âœ… æ£€ç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(docs)} ä¸ªç›¸å…³æ–‡æ¡£")
        
        if not docs:
            print(f"âš ï¸ æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£ã€‚")
            print(f"ğŸ” å»ºè®®æ£€æŸ¥å‘é‡åº“å†…å®¹: è¿è¡Œ python src/split_text.py ç¡®è®¤å‘é‡åº“æ˜¯å¦æ­£ç¡®æ„å»º")
            return
        
        # 2. ç”Ÿæˆå›ç­”ï¼ˆè¿™é‡Œç®€åŒ–å¤„ç†ï¼Œä»…å±•ç¤ºæ£€ç´¢ç»“æœï¼‰
        print(f"\nğŸ” æ‰¾åˆ° {len(docs)} ä¸ªç›¸å…³ç»“æœï¼š")
        for i, doc in enumerate(docs, 1):
            print(f"{i}. æ¥æº: {doc.metadata.get('source', 'æœªçŸ¥æ¥æº')}")
            print(f"   å†…å®¹: {doc.page_content[:100]}...\n")
            
    except Exception as e:
        logger.error(f"âŒ é—®ç­”è¿‡ç¨‹å‡ºé”™: {e}")
        print(f"âš ï¸ é—®ç­”è¿‡ç¨‹å‡ºé”™: {str(e)}")

# ================== è°ƒè¯•å‡½æ•° ==================
def debug_vectorstore():
    """ç›´æ¥ä½¿ç”¨chromadbå®¢æˆ·ç«¯è°ƒè¯•å‘é‡åº“"""
    try:
        import chromadb
        logger.info("âœ… å¯¼å…¥chromadbæˆåŠŸ")
        
        # è·å–å‘é‡åº“ç»å¯¹è·¯å¾„
        abs_vector_path = os.path.abspath(VECTOR_DB_PATH)
        logger.info(f"ğŸ” å‘é‡åº“ç»å¯¹è·¯å¾„: {abs_vector_path}")
        
        # ç›´æ¥åˆå§‹åŒ–chromadbå®¢æˆ·ç«¯
        client = chromadb.PersistentClient(path=abs_vector_path)
        logger.info(f"âœ… åˆå§‹åŒ–chromadbå®¢æˆ·ç«¯æˆåŠŸ")
        
        # åˆ—å‡ºæ‰€æœ‰é›†åˆ
        collections = client.list_collections()
        logger.info(f"âœ… æ‰¾åˆ° {len(collections)} ä¸ªé›†åˆ")
        for coll in collections:
            logger.info(f"   - é›†åˆåç§°: {coll.name}, æ–‡æ¡£æ•°é‡: {coll.count()}")
            
        # å°è¯•ç›´æ¥è®¿é—®qwen_ragé›†åˆ
        try:
            collection = client.get_collection("qwen_rag")
            logger.info(f"âœ… æˆåŠŸè®¿é—®é›†åˆ: {collection.name}")
            logger.info(f"ğŸ“Š é›†åˆç»Ÿè®¡ä¿¡æ¯: æ–‡æ¡£æ•°é‡={collection.count()}")
            
            # å¦‚æœæœ‰æ–‡æ¡£ï¼Œå°è¯•è·å–ä¸€äº›æ–‡æ¡£
            if collection.count() > 0:
                results = collection.get(limit=5)
                logger.info(f"âœ… è·å–åˆ° {len(results['ids'])} ä¸ªæ–‡æ¡£ID: {results['ids'][:5]}")
            else:
                logger.warning("âš ï¸ é›†åˆä¸­æ²¡æœ‰æ–‡æ¡£")
        except Exception as e:
            logger.error(f"âŒ æ— æ³•è®¿é—®é›†åˆ: {e}")
    except Exception as e:
        logger.error(f"âŒ è°ƒè¯•å‘é‡åº“å¤±è´¥: {e}")

# ================== æµ‹è¯•å‡½æ•° ==================
if __name__ == "__main__":
    logger.info("ğŸš€ RAG é—®ç­”ç³»ç»Ÿå¯åŠ¨")
    
    # å…ˆè¿è¡Œè°ƒè¯•å‡½æ•°
    debug_vectorstore()
    
    # æµ‹è¯•é—®é¢˜
    test_questions = [
        "æŠ¥å‘Šå†™äº†ä»€ä¹ˆï¼Ÿ",
        "sample.pdf æ˜¯ä»€ä¹ˆå†…å®¹ï¼Ÿ",
        "LangChain å¯ä»¥è¯»å–ä»€ä¹ˆæ–‡ä»¶ï¼Ÿ"
    ]
    
    for question in test_questions:
        print("--------------------------------------------------")
        ask_rag_question(question)
        print("--------------------------------------------------")
        time.sleep(2)  # é¿å…è¯·æ±‚è¿‡å¿«
    
    logger.info("ğŸ RAG é—®ç­”ç³»ç»Ÿæµ‹è¯•å®Œæˆ")