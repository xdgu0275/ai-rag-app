# qwen_embedding_rag.py - è°ƒç”¨é€šä¹‰åƒé—® Embedding API + Chroma å­˜å‚¨
import json
import os
import time
import logging
import dotenv
from typing import List, Optional, Dict, Any

# åŠ è½½ç¯å¢ƒå˜é‡
dotenv.load_dotenv()

# æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
)
logger = logging.getLogger(__name__)

# å‘é‡åº“
from langchain_chroma import Chroma
from chromadb.config import Settings

# ç¦ç”¨ Chroma telemetry
logger.info("ğŸ”§ å·²è®¾ç½®ç¦ç”¨ Chroma telemetry")
from langchain.docstore.document import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter

# é€šä¹‰åƒé—® SDK
import dashscope
from dashscope import TextEmbedding

# ================== é…ç½® ==================
# ä»ç¯å¢ƒå˜é‡è·å– API Key
DASHSCOPE_API_KEY = os.getenv("DASHSCOPE_API_KEY")
if not DASHSCOPE_API_KEY:
    raise ValueError("è¯·è®¾ç½®ç¯å¢ƒå˜é‡ DASHSCOPE_API_KEY")

dashscope.api_key = DASHSCOPE_API_KEY

# é…ç½®å‚æ•°
EMBEDDING_MODEL = os.getenv("EMBEDDING_MODEL", "text-embedding-v2")  # é€šä¹‰åƒé—® Embedding æ¨¡å‹å
VECTOR_DB_PATH = os.getenv("VECTOR_DB_PATH", "vectorstore_qwen")
os.makedirs(VECTOR_DB_PATH, exist_ok=True)

# åˆ†å—é…ç½®
CHUNK_SIZE = int(os.getenv("CHUNK_SIZE", "500"))
CHUNK_OVERLAP = int(os.getenv("CHUNK_OVERLAP", "50"))
BATCH_SIZE = int(os.getenv("BATCH_SIZE", "5"))  # é€šä¹‰åƒé—®å…è´¹ç‰ˆé™æµï¼šæ¯åˆ†é’Ÿ 5 æ¬¡è¯·æ±‚
REQUEST_INTERVAL = int(os.getenv("REQUEST_INTERVAL", "12"))  # è¯·æ±‚é—´éš”æ—¶é—´(ç§’)
MAX_RETRIES = int(os.getenv("MAX_RETRIES", "3"))  # æœ€å¤§é‡è¯•æ¬¡æ•°

current_dir = os.path.dirname(os.path.abspath(__file__))
INPUT_JSON = os.path.join(current_dir, "docs.json")

# æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
)
logger = logging.getLogger(__name__)

# ================== é€šä¹‰åƒé—® Embedding ç±» ==================
class QwenEmbeddings:
    """å°è£…é€šä¹‰åƒé—® Embedding API è°ƒç”¨"""
    def __init__(self, model: str = EMBEDDING_MODEL):
        self.model = model

    def _call_api(self, texts: List[str]) -> List[List[float]]:
        """è°ƒç”¨ DashScope Embedding APIï¼ŒåŒ…å«é‡è¯•æœºåˆ¶"""
        retry_count = 0
        while retry_count < MAX_RETRIES:
            try:
                logger.info(f"ğŸ“¤ å‘é€è¯·æ±‚: {len(texts)} ä¸ªæ–‡æœ¬ (é‡è¯•: {retry_count}/{MAX_RETRIES-1})")
                response = TextEmbedding.call(
                    model=self.model,
                    input=texts
                )
                logger.info(f"ğŸ“¥ æ”¶åˆ°å“åº”: çŠ¶æ€ç  {response.status_code}")
                if response.status_code == 200:
                    # æ£€æŸ¥å“åº”ç»“æ„
                    if not hasattr(response, 'output') or 'embeddings' not in response.output:
                        raise Exception("API å“åº”æ ¼å¼ä¸æ­£ç¡®ï¼Œç¼ºå°‘ embeddings å­—æ®µ")
                    embeddings_data = response.output['embeddings']
                    # æå–æ¯ä¸ª embedding å‘é‡
                    results = [item['embedding'] for item in embeddings_data]
                    logger.info(f"âœ… æˆåŠŸè·å– {len(results)} ä¸ªåµŒå…¥å‘é‡")
                    return results
                elif response.status_code in [429, 500, 502, 503, 504]:
                    # é™æµæˆ–æœåŠ¡å™¨é”™è¯¯ï¼Œé‡è¯•
                    retry_count += 1
                    wait_time = REQUEST_INTERVAL * (2 ** retry_count)  # æŒ‡æ•°é€€é¿
                    logger.warning(f"âš ï¸ API é”™è¯¯: {response.code} - {response.message}, ç­‰å¾… {wait_time} ç§’åé‡è¯•")
                    time.sleep(wait_time)
                else:
                    raise Exception(f"API é”™è¯¯: {response.code} - {response.message}")
            except Exception as e:
                retry_count += 1
                logger.error(f"âŒ Embedding è°ƒç”¨å¤±è´¥: {str(e)}, é‡è¯• {retry_count}/{MAX_RETRIES-1}")
                if retry_count < MAX_RETRIES:
                    wait_time = REQUEST_INTERVAL * (2 ** retry_count)
                    time.sleep(wait_time)
                else:
                    raise

    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        """æ‰¹é‡ç”Ÿæˆæ–‡æ¡£åµŒå…¥ï¼ˆè‡ªåŠ¨åˆ†æ‰¹ï¼‰"""
        all_embeddings = []
        for i in range(0, len(texts), BATCH_SIZE):
            batch = texts[i:i+BATCH_SIZE]
            batch_num = i // BATCH_SIZE + 1
            logger.info(f"ğŸŒ è°ƒç”¨é€šä¹‰åƒé—® Embedding (æ‰¹æ¬¡: {batch_num}/{(len(texts)-1)//BATCH_SIZE + 1}, æ•°é‡: {len(batch)})")
            batch_embeds = self._call_api(batch)
            all_embeddings.extend(batch_embeds)
            logger.info(f"âœ… æ‰¹æ¬¡ {batch_num} å¤„ç†å®Œæˆ")
            # é¿å…é™æµ
            if i + BATCH_SIZE < len(texts):  # ä¸æ˜¯æœ€åä¸€æ‰¹æ‰éœ€è¦ç­‰å¾…
                time.sleep(REQUEST_INTERVAL)
        return all_embeddings

    def embed_query(self, text: str) -> List[float]:
        """ä¸ºæŸ¥è¯¢ç”ŸæˆåµŒå…¥"""
        return self._call_api([text])[0]


# ================== ä¸»ç¨‹åº ==================
def main():
    logger.info("ğŸš€ å¼€å§‹ä½¿ç”¨é€šä¹‰åƒé—® Embedding è¿›è¡Œå‘é‡åŒ–")

    # 1. è¯»å– docs.json
    try:
        with open(INPUT_JSON, "r", encoding="utf-8") as f:
            docs = json.load(f)
        logger.info(f"âœ… åŠ è½½ {len(docs)} ä¸ªæ–‡æ¡£")
    except FileNotFoundError:
        logger.error("âŒ æ‰¾ä¸åˆ° ../docs.json")
        return
    except Exception as e:
        logger.error(f"âŒ è¯»å–å¤±è´¥: {e}")
        return

    # 2. åˆ†å—
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=CHUNK_SIZE,
        chunk_overlap=CHUNK_OVERLAP,
        separators=["\n\n", "\n", "ã€‚", "ï¼", "ï¼Ÿ", "ï¼›", " ", ""]
    )
    all_chunks = []

    for doc in docs:
        if doc.get("status") != "success":
            continue
        content = doc.get("content", "").strip()
        if not content or len(content) < 10:
            continue

        chunks = splitter.split_text(content)
        for i, chunk in enumerate(chunks):
            clean_chunk = chunk.replace("\r", "").strip()
            if len(clean_chunk) < 5:
                continue
            all_chunks.append(Document(
                page_content=clean_chunk,
                metadata={"source": doc["filename"], "chunk_id": i}
            ))
        logger.info(f"âœ‚ï¸  {doc['filename']} â†’ {len(chunks)} ä¸ªå—")

    if not all_chunks:
        logger.error("âŒ æ²¡æœ‰å¯å¤„ç†çš„æ–‡æœ¬å—")
        return
    logger.info(f"âœ… å…±ç”Ÿæˆ {len(all_chunks)} ä¸ªæ–‡æœ¬å—")

    # 3. åˆå§‹åŒ–é€šä¹‰åƒé—® Embedding
    try:
        embeddings = QwenEmbeddings()
        # æµ‹è¯•è°ƒç”¨
        test_embed = embeddings.embed_query("æµ‹è¯•")
        logger.info(f"âœ… é€šä¹‰åƒé—® Embedding åˆå§‹åŒ–æˆåŠŸï¼Œå‘é‡ç»´åº¦: {len(test_embed)}")
    except Exception as e:
        logger.error("âŒ åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·æ£€æŸ¥ API Key æˆ–ç½‘ç»œ")
        return

    # 4. åˆ›å»º Chroma å‘é‡åº“
    try:
        logger.info(f"ğŸ”„ å¼€å§‹åˆ›å»ºå‘é‡åº“ï¼Œå…± {len(all_chunks)} ä¸ªæ–‡æ¡£å—")
        # é…ç½® Chroma å®¢æˆ·ç«¯ï¼Œç¦ç”¨ telemetry
        settings = Settings(anonymized_telemetry=False)
        logger.info("ğŸ”§ å·²é€šè¿‡ Settings ç¦ç”¨ Chroma telemetry")

        vectorstore = Chroma.from_documents(
            documents=all_chunks,
            embedding=embeddings,
            persist_directory=VECTOR_DB_PATH,
            collection_name="qwen_rag",
            client_settings=settings
        )
        logger.info(f"âœ… å‘é‡åº“å·²åˆ›å»ºå¹¶æŒä¹…åŒ–: {VECTOR_DB_PATH}")
        # æ˜¾å¼æŒä¹…åŒ–
        vectorstore.persist()
        logger.info(f"âœ… å‘é‡åº“å·²æ˜¾å¼æŒä¹…åŒ–")
    except Exception as e:
        logger.error(f"âŒ å‘é‡åº“åˆ›å»ºå¤±è´¥: {str(e)}")
        return

    # 5. æœç´¢æµ‹è¯•
    try:
        logger.info("ğŸ” å¼€å§‹æœç´¢æµ‹è¯•")
        query = "æŠ¥å‘Šå†™äº†ä»€ä¹ˆï¼Ÿ"
        logger.info(f"ğŸ“ æœç´¢æŸ¥è¯¢: {query}")
        results = vectorstore.similarity_search(query, k=2)
        logger.info(f"âœ… æ‰¾åˆ° {len(results)} ä¸ªç›¸å…³ç»“æœ")
        logger.info(f"\nğŸ” æœç´¢ '{query}' çš„ç»“æœï¼š")
        for i, r in enumerate(results):
            logger.info(f"{i+1}. æ¥æº: {r.metadata['source']}")
            logger.info(f"   å†…å®¹: {r.page_content[:100]}...\n")
        logger.info("âœ… æœç´¢æµ‹è¯•å®Œæˆ")
    except Exception as e:
        logger.error(f"âŒ æœç´¢æµ‹è¯•å¤±è´¥: {str(e)}", exc_info=True)

    logger.info("ğŸ ç¨‹åºæ‰§è¡Œå®Œæˆ")

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        logger.error(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {str(e)}", exc_info=True)
    logger.info("ğŸ ç¨‹åºæ‰§è¡Œå®Œæˆ")